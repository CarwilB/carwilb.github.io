<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Carwil Bjork-James">
<meta name="dcterms.date" content="2025-12-26">
<meta name="description" content="An evolving list of smart, often skeptical takes on Generative AI">

<title>What you should know about Artificial Intelligence | Carwil Bjork-James ‚Äì Carwil Bjork-James</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../posts/ai-wikimedia.html" rel="next">
<link href="../index.qmd#posts" rel="prev">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-b758ccaa5987ceb1b75504551e579abf.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-8a9afb11e4d49f1e3d1547ea1b6c5d64.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-383975dd00985b4a925bd0c258f37292.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-8a9afb11e4d49f1e3d1547ea1b6c5d64.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar docked slimcontent quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../index.html#posts">Posts</a></li><li class="breadcrumb-item"><a href="../posts/ai-links.html">What you should know about Artificial Intelligence</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../images/carwil-bjork-james-hex.png" alt="Carwil Bjork-James in a data science hexagon" class="sidebar-logo light-content py-0 d-lg-inline d-none">
      <img src="../images/carwil-bjork-james-hex.png" alt="Carwil Bjork-James in a data science hexagon" class="sidebar-logo dark-content py-0 d-lg-inline d-none">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Carwil Bjork-James</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://ultimateconsequences.github.io" title="Ultimate Consequences Project Website" class="quarto-navigation-tool px-1" aria-label="Ultimate Consequences Project Website"><i class="bi bi-globe"></i></a>
    <a href="https://woborders.blog" title="Carwil without Borders" class="quarto-navigation-tool px-1" aria-label="Carwil without Borders"><i class="bi bi-wordpress"></i></a>
    <a href="https://mastodon.online/@Carwil" title="Carwil on Mastodon" class="quarto-navigation-tool px-1" aria-label="Carwil on Mastodon"><i class="bi bi-mastodon"></i></a>
    <a href="https://twitter.com/CarwilBJ" title="Carwil Bjork-James on Twitter" class="quarto-navigation-tool px-1" aria-label="Carwil Bjork-James on Twitter"><i class="bi bi-twitter"></i></a>
    <a href="https://carwilb.github.io/twitter" title="Twitter archive" class="quarto-navigation-tool px-1" aria-label="Twitter archive"><i class="bi bi-twitter"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../about-bio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Biography</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../index.html#posts" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Posts</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/ai-links.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">What you should know about Artificial Intelligence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/ai-wikimedia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Wikimedia Foundation, Wikipedia, and Artificial Intelligence</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/archived-welcome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/cfp-aaa-violence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Panel on Researching Violence for AAA 2025</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/israel-palestine-fatalities-40k.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Palestinian fatalities surpass 40,000 in under 11 months</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/palestine-archipelago.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Palestine Archipelago</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/political-violence-2022.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conflict deaths in Bolivia, 2022</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/political-violence-2023-24.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conflict deaths in Bolivia, 2023‚Äì24</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/redirect-generator.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Wikipedia Redirect Generator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../posts/sexual-assault-avoidance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What do you do to avoid sexual assault?</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../index.html#teaching-notes" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Teaching Notes</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../teaching/history-anthro-w10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Landmarks in conceptualizing the ethnographic field by Malinowski and Gluckman</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../teaching/history-anthro-w11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Margaret Mead</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../teaching/history-anthro-w12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Gifts, Boundaries, and Taboos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../teaching/history-anthro-w14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Anthropological grounds for a ‚Äúrevolution in kinship‚Äù</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../teaching/history-anthro-w2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">When did anthropology begin in the Western Hemisphere?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../teaching/history-anthro-w3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Anthropology and the Enlightenment</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../teaching/history-anthro-w4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ninetenth-Century Evolutionary Anthropology</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../teaching/history-anthro-w5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nineteenth-century North American ethnography by Mooney and Morgan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../teaching/history-anthro-w8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Boas, Rivet, and the End of the Craniometry of Race</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../teaching/intro-life-debt-update.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">‚ÄúLife and Debt‚Äù Follow-up: Jamaica and Structural Adjustment</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../teaching/intro-stephanie-black.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Filmmaker Stephanie Black on ‚ÄúLife and Debt‚Äù</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../teaching/intro-three-gorges.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Some updates on the Three Gorges Dam</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../index.html#posts">Posts</a></li><li class="breadcrumb-item"><a href="../posts/ai-links.html">What you should know about Artificial Intelligence</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">What you should know about Artificial Intelligence</h1>
</div>

<div>
  <div class="description">
    An evolving list of smart, often skeptical takes on Generative AI
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Carwil Bjork-James </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 26, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introductions-to-generative-ai" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="introductions-to-generative-ai">Introductions to Generative AI</h2>
<ul>
<li><strong>A jargon-free explanation of how AI large language models work</strong> (<a href="https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/">ArsTechnica article</a>): a particularly eloquent primer on the underlying technology.</li>
<li><strong><em>Possible Minds: Twenty-Five Ways of Looking at AI</em></strong>:<span class="citation" data-cites="brockmanPossibleMindsTwentyfive2019"><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></span> If you want to know both the existential risk perspective and the here‚Äôs why human four-year-olds maintain intuitive knowledge ungrasped by AI, and especially how people who are doing this work see it, this is a thoughtful book filled with long-term (but not ‚Äúlong-termist‚Äù) perspectives.</li>
<li><strong><em>Artificial Intelligence: A Guide for Thinking Humans:</em></strong><span class="citation" data-cites="mitchellArtificialIntelligenceGuide2019"><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></span> Despite being published in 2019, this book by Melanie Mtichell (more on her below) is so technically smart and rigorous that it anticipates many of the limitations, quandaries, and debates that surround generative AI.</li>
<li><strong><em>Machines of Loving Grace</em></strong>:<span class="citation" data-cites="markoffMachinesLovingGrace2015"><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></span> John Markoff‚Äôs deep history of modern computer design and engineering traces how designers of human‚Äìcomputer interactions have been pulled either towards Artificial Intelligence (duplicating human intelligence in software systmes) or Intelligence Augmentation (building tools that extend human capacities).</li>
<li><strong>ChatGPT Is Not Intelligent</strong> (<a href="https://podcasts.apple.com/us/podcast/chatgpt-is-not-intelligent-w-emily-m-bender/id1507621076?i=1000608745281">podcast episode</a>) w/ Emily M. Bender.</li>
<li>Big picture argument (<a href="https://www.nytimes.com/2023/01/06/opinion/ezra-klein-podcast-gary-marcus.html">podcast episode</a>) from Gary Marcus that <strong>the current big-data approach won‚Äôt produce Artificial General Intelligence</strong>, but could contribute to it.</li>
<li>On <strong>how (even buggy and hallucinatory) LLM output can help you with programming</strong>, if you‚Äôre a programmer: https://simonwillison.net/2023/Apr/8/llms-break-the-internet/</li>
<li><strong>AI and the Illusion of Intelligence</strong> (<a href="https://www.coursera.org/learn/ai-and-the-illusion-of-intelligence">Coursera course</a>): a short, smart online course that takes you from Turing‚Äôs article inventing his famous test through the development of LLMs, with a thoughtful argument about intelligence augmentation through technology.</li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;John Brockman and ProQuest, <em>Possible minds: twenty-five ways of looking at AI</em> (Penguin Press, 2019).</p></div><div id="fn2"><p><sup>2</sup>&nbsp;Melanie Mitchell, <em>Artificial intelligence: a guide for thinking humans</em>, First edition. (Farrar, Straus; Giroux, 2019).</p></div><div id="fn3"><p><sup>3</sup>&nbsp;John Markoff, <em>Machines of loving grace: The quest for common ground between humans and robots</em>, First edition (ECCO, 2015), <a href="http://books.google.com/books?vid=isbn9780062266682">http://books.google.com/books?vid=isbn9780062266682</a>.</p></div></div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/artificial-intelligence-machine-2.jpg" class="img-fluid figure-img"></p>
<figcaption>Artificial intelligence machine synthesized by Adobe Firefly</figcaption>
</figure>
</div>
</section>
<section id="ai-news-sources" class="level2">
<h2 class="anchored" data-anchor-id="ai-news-sources">AI news sources</h2>
<ul>
<li><strong>Changelog</strong> and its <a href="https://practicalai.fm/">sub-podcast</a> <strong>Practical AI</strong> ‚Äî Developers talking about technology. Example episodes: especially clear <a href="https://practicalai.fm/302">take on Deep Seek</a>; interview with <a href="https://practicalai.fm/293">National Institute of Standards and Technology staffer regulating AI</a>.</li>
<li><strong>TED AI Show</strong> podcast ‚Äî Definitely credulous about AI‚Äôs potential, but lots of in-person interviews with AI players, giving insight on how companies are envisioning their plans. Examples: This <a href="https://open.spotify.com/episode/4GBoicwLLewdblKMxjR5yK?si=WAwGDEhKS7iUMjO4Pd9A9w">episode</a> taught me more about Google than I knew before.</li>
<li><strong>Tech Won‚Äôt Save Us</strong> <a href="https://techwontsave.us/">podcast</a> ‚Äî Combines pessimism on the tech hype cycle with political critique of the direction of Big Tech.</li>
<li>Also for an often technical discussion, there is <strong>Machine Learning Street Talk</strong> <a href="https://open.spotify.com/show/02e6PZeIOdpmBGT9THuzwR?si=f3c82c3cc39b42e4">podcast</a> ‚Äî Recent more accessible episodes include <a href="https://creators.spotify.com/pod/show/machinelearningstreettalk/episodes/GSMSymbolic-paper---Iman-Mirzadeh-Apple-e30dhvp">an interview with the Apple researcher</a> who ‚Äú<a href="https://arstechnica.com/ai/2024/10/llms-cant-perform-genuine-logical-reasoning-apple-researchers-suggest/">exposed deep cracks in LLMs‚Äô ‚Äúreasoning‚Äù capabilities</a>‚Äù and <a href="https://creators.spotify.com/pod/show/machinelearningstreettalk/episodes/ARC-Prize-v2-Launch--Francois-Chollet-and-Mike-Knoop-e30k12p">a profile of the ARC v2 challenge</a> on human-like reasoning capabilities. You can see the challenge itself in <a href="https://www.nytimes.com/interactive/2025/03/26/business/ai-smarter-human-intelligence-puzzle.html">this <em>NYT</em> interactive</a>.</li>
</ul>
</section>
<section id="persistent-critical-voices" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="persistent-critical-voices">Persistent critical voices:</h2>
<ul>
<li><strong>Emily Bender</strong> (<a href="https://en.wikipedia.org/wiki/Emily_M._Bender">Wikipedia</a> | <a href="https://scholar.google.com/citations?user=9r_f1w4AAAAJ&amp;hl=en&amp;oi=ao">Google Scholar</a>), a linguist who entered the Generative AI discussion as an expert on large-language models. Co-author of ‚Äú<a href="https://dl.acm.org/doi/10.1145/3442188.3445922">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ü¶ú</a>‚Äù research paper with Timnit Gebru. Bender‚Äôs take is that hype is driving the AI discussion, and that there are substantive ethical problems with current models. More than other researchers, Bender inclines towards detailed collaborative critiques on questions like: <a href="https://bdtechtalks.com/2021/12/06/ai-benchmarks-limitations/">Can AI‚Äôs that pass human benchmark tests be said to have capacities they test for?</a> <a href="https://dl.acm.org/doi/full/10.1145/3649468">What are the dangers of using AI for search?</a> Bender has a new book out in 2025, <em>The AI Con</em>,<span class="citation" data-cites="benderAIConHow2025"><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></span> making a practical case that LLMs are being oversold and an ethical case they aren‚Äôt building the future we want.</li>
<li><strong>Gary Marcus</strong> (<a href="https://en.wikipedia.org/wiki/Gary_Marcus">Wikipedia</a> <a href="https://garymarcus.substack.com/">Substack blog</a>) ‚Äî researcher and proponent of a structured approach to building artificial intelligence, but who thinks that hallucinations and failure to understand edge cases are invariable traits of neural network architectures. Marcus has emerged as a sharp critic of the current generative AI wave as unlikely to every generate sophisticated intelligence and a potential diversion of hundreds of billions of dollars and societal distrust in an unproductive direction. Marcus published his views in <em>Taming Silicon Valley</em> (2024)<strong>.</strong><span class="citation" data-cites="marcusTamingSiliconValley2024"><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></span></li>
<li><strong>Ed Zitron</strong> ‚Äî Technology critic and writer. Focused on declining tech user experience and <a href="https://www.wheresyoured.at/subprimeai/">risks of a financial bubble</a> around generative AI. His general take is that generative AI has yet to show a vital use case and could dramatically underperform market expectations.</li>
<li><strong>Jaron Lanier</strong>, whose <em>You Are Not a Gadget</em> and <em>Who Owns the Future?</em> raise important questions about power and economy of technology, while accepting that technology will solve whatever problems it creates. <em>Who Owns the Future</em> also provides a smart typology of perspectives on technology.</li>
<li><strong>Cory Doctorow</strong>, futurist sci-fi writer with a hard economic critique of Big Tech in <em>Chokepoint Capitalism</em>.</li>
<li><strong>Shoshana Zuboff</strong>. It‚Äôs worth taking a moment and imagine AI chatbots and on-the-horizon agents, not as potentially intelligent machines, but rather as data collectors to the corporations that she thoroughly laid out in <em>The Age of Surveillance Capitalism</em>.</li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;Emily M. Bender and Alex Hanna, <em>The AI Con: How to Fight Big Tech<span>‚Äô</span>s Hype and Create the Future We Want <span></span> Exposing Surveillance Capitalism and Artificial Intelligence Myths in Information Technology Today</em> (Harper, 2025).</p></div><div id="fn5"><p><sup>5</sup>&nbsp;Gary F. Marcus, <em>Taming Silicon Valley: How We Can Ensure That AI Works for Us</em> (The MIT Press, 2024).</p></div></div></section>
<section id="outspoken-ai-scientists" class="level2">
<h2 class="anchored" data-anchor-id="outspoken-ai-scientists">Outspoken AI scientists:</h2>
<ul>
<li><strong>Fei-Fei Li</strong>, Director of Stanford‚Äôs <a href="https://hai.stanford.edu/">Human-Centered AI Institute</a>, a crossover from AI science to humanities who invented the term ‚Äúfoundation models.‚Äù</li>
<li><strong>Geoffrey Hinton</strong>, researcher into neural-network-based machine learning. His experience with creating vision models whose internal workings are inscrutable have convinced him that knowing how AI works isn‚Äôt essential to believing that it works. For good insight on this view, and contrasts with Li, listen to <a href="https://podcasts.apple.com/us/podcast/geoffrey-hinton-in-conversation-with-fei-fei-li/id1524902736?i=1000672242078">Geoffrey Hinton in conversation with Fei-Fei Li</a></li>
</ul>
<p>A notable moment in the the Hinton‚ÄìLi conversation comes at 1h18, where they are asked whether ‚Äúwe are at the point where we can say [LLMs/foundational models] have understanding and intelligence?‚Äù Hinton‚Äôs answer is at 1h30. Li responds at 1h35.</p>
<p>Also, the core of Hinton‚Äôs perspective may be this definition of education: ‚ÄúSo the way we exchange knowledge, roughly speaking, this is something of a simplification, but I produce a sentence and you figure out what you have to change in your brain, so you might have said that, that is if you trust me.‚Äù ‚ÄúWhat I want to claim is that these millions of features and billions of interactions between features <em>are</em> understanding. ‚Ä¶ If you ask, how do we understand, this is the best model of how we understand.‚Äù (<a href="https://www.youtube.com/watch?v=N1TEjTeQeg0&amp;t=39s">‚ÄúWill digital intelligence replace biological intelligence?‚Äù Romanes Lecture</a> at 14m28s )</p>
<ul>
<li><strong>Melanie Mitchell</strong> (<a href="https://en.wikipedia.org/wiki/Melanie_Mitchell">Wikipedia</a> | <a href="https://aiguide.substack.com/">Substack blog</a>) ‚Äî A very hands-on research expert on AI development and benchmarking who asks hard questions. She‚Äôs the author of</li>
</ul>
<p><strong>Melanie Mitchell</strong>‚Äôs recent research has been examining the cognitive processes in LLM-based AI systems, including through experiments. In a recent talk, <a href="https://www.youtube.com/watch?v=yKbeCvOKvMc&amp;t=1749s">‚ÄúEvaluating Cognitive Capacities in AI Systems‚Äù</a> at the 2025 Natural Philosophy Symposium at Johns Hopkins, she lays out this work. Mitchell argues that increasing performance by AI systems seems grounded in multiplying numbers of heuristic associations rather than the ‚Äúabstract reasoning‚Äù named by the labs creating current foundation models. She and collaborators have developed experiments to confirm this, in part by demonstrating that AI model performance declines when letters are swapped out from a simple sequence task (an experiment much like the well-publicized Apple paper on distractor information interfering with reasoning). She also offers one of the clearest explanations of the ARC abstract reasoning tests and talks about how her lab has been creating simpler versions of these tests to probe just how LLMs handle abstractions, when they can.</p>
<p>On the B-side, if you will, of Mitchell‚Äôs lecture video come comments from <strong>Alison Gopnik</strong>. Her focus is reframing AI not as a self-conscious (or eventually self-conscious) reasoning technology, but rather as a novel form of social aggregation, best thought of as a successor to the library or the market, or even to the state and regulation. She argues that it‚Äôs pointless to ask who is smarter: a scientist or a library. Indeed, this is a kind of ‚Äúcategory error‚Äù that misses the more important point: what can one, or many scientists do with a library that they couldn‚Äôt do without one? When thought of as a social aggregator that lends power to new actions, we end up a lot closer to the notion of ‚ÄúIntelligence Augmentation,‚Äù a converse goal to Artificial Intelligence that‚Äôs explored in <em>Possible Minds</em> and in <em>Machines of Loving Grace</em>.)</p>
<p>(For what it‚Äôs worth, I find the social aggregation metaphor to be a much clearer description of what the text tha pours out from AI chatbot firehose than the intelligent agent metaphor. It explains how fully formed units of code that appeared elsewhere sometimes show up, and how interpolated summary segments also show up. As Melanie Mitchell writes elsewhere, and I‚Äôm paraphrasing here, ‚Äúlike Soylent Green, AI is people.‚Äù)</p>
</section>
<section id="visions-of-ai-entrepreneurs-and-business-leaders" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="visions-of-ai-entrepreneurs-and-business-leaders">Visions of AI entrepreneurs and business leaders</h2>
<ul>
<li><p><strong>Mustafa Suleyman</strong>, CEO of Microsoft AI, <a href="https://www.youtube.com/watch?v=KKNCiRWd_j0">His talk, ‚ÄúWhat Is an AI Anyway?,‚Äù characterizes AI as ‚Äúa new digital species‚Äù</a></p></li>
<li><p><strong>Dario Amodei</strong>, CEO of Anthropic. February <a href="https://www.nytimes.com/2025/02/28/podcasts/hardfork-anthropic-dario-amodei.html">interview on Hard Fork</a>. November <a href="https://www.nytimes.com/2025/12/07/business/dealbook/dario-amodei-dealbook.html">appearance on NYT DealBook</a> (<a href="https://www.youtube.com/watch?v=FEj7wAjwQIk">video</a>). In essence, Amodei who has <a href="https://www.darioamodei.com/essay/machines-of-loving-grace">prophesied the near-term arrival of AGI</a> continues to believe that scaling up LLMs is the way to get there.</p></li>
<li><p><strong>Sam Altman</strong>, CEO of OpenAI: Instead of listening to Sam Altman, let me suggest reading one of the two up-close books on Altman and OpenAI‚Äôs rise published this year: Karen Hao‚Äôs <em>Empire of AI</em><span class="citation" data-cites="haoEmpireAIDreams2025"><a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></span> which describes the AI industry as not just about its product, but about the acquisition of creative labor (through training data) and coordination of human labor and energy (through its overseas workforce and data centers) in ways that echo colonial enterprises. Keach Hagey‚Äôs <em>The Optimist: Sam Altman, OpenAI, and the Race to Invent the Future</em><span class="citation" data-cites="hagey2025"><a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></span> is more, well, optimistic. As a <a href="https://www.nytimes.com/2025/05/19/books/review/empire-of-ai-karen-hao-the-optimist-keach-hagey.html">comparative review</a> put it, Hagey ‚Äústands Altman as the secular prophet preaching human progress and boundless optimism.‚Äù</p>
<p>This interview quote from Karen Hao on Altman is informative, suggesting that his ability to shift narratives makes him something of an unreliable narrator on even his own views:</p>
<blockquote class="blockquote">
<p>‚ÄúHe‚Äôs a once-in-a-generation fundraising talent. That is his particular skill. And he‚Äôs also a once-in-a-generation storytelling talent, which is effectively why he‚Äôs so good at fundraising. He is able to paint these extremely persuasive visions of the future. He was already prominent within Silicon Valley, and Silicon Valley very much runs on stories and telling stories about the future. And one of the things that I sort of concluded through the reporting of my book is that when he says something to someone, what he‚Äôs saying is more tightly correlated with what he thinks they need to hear than what he actually believes or the ground truth of the thing. He‚Äôs able to say the things that really provoke people to kind of rally towards a general, broad, sweeping mission that he paints.<span class="citation" data-cites="inskeepJournalistKarenHao2025"><a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></span></p>
</blockquote></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;Karen Hao, <em>Empire of AI: Dreams and Nightmares in Sam Altman‚Äôs OpenAI</em> (Penguin Press, 2025).</p></div><div id="fn7"><p><sup>7</sup>&nbsp;Keach Hagey, <em>The optimist: Sam Altman, OpenAI, and the race to invent the future</em>, First edition (W.W. Norton &amp; Company, 2025).</p></div><div id="fn8"><p><sup>8</sup>&nbsp;Steve Inskeep, <span>‚ÄúJournalist Karen Hao Discusses Her Book ‚ÄôEmpire of AI‚Äô,‚Äù</span> <em>NPR</em>, May 20, 2025, <a href="https://www.npr.org/2025/05/20/nx-s1-5334670/journalist-karen-hao-discusses-her-book-empire-of-ai">https://www.npr.org/2025/05/20/nx-s1-5334670/journalist-karen-hao-discusses-her-book-empire-of-ai</a>.</p></div><div id="fn9"><p><sup>9</sup>&nbsp;Timnit Gebru and √âmile P. Torres, <span>‚ÄúThe TESCREAL Bundle: Eugenics and the Promise of Utopia Through Artificial General Intelligence,‚Äù</span> <em>First Monday</em>, ahead of print, April 14, 2024, <a href="https://doi.org/10.5210/fm.v29i4.13636">https://doi.org/10.5210/fm.v29i4.13636</a>.</p></div></div><p>A suprising, one could also say disturbing, share of AI visions are wrapped up in some peculiar ideas about the future that Timnit Gebru and √âmile P. Torres have christened the <strong>TESCREAL bundle</strong>.<span class="citation" data-cites="gebruTESCREALBundleEugenics2024"><a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></span> (Gebru is a Google engineer fired for her critical views. Torres is a philosopher who was once a transhumanist.)</p>
<p>The bundle consists of: ‚Äú<a href="https://en.wikipedia.org/wiki/Transhumanism" title="Transhumanism">Transhumanism</a>, <a href="https://en.wikipedia.org/wiki/Extropianism" title="Extropianism">Extropianism</a>, <a href="https://en.wikipedia.org/wiki/Singularitarianism" title="Singularitarianism">Singularitarianism</a>, (modern) Cosmism, <a href="https://en.wikipedia.org/wiki/Rationalist_community" title="Rationalist community">Rationalists</a> (the internet community), <a href="https://en.wikipedia.org/wiki/Effective_Altruism" title="Effective Altruism">Effective Altruism</a>, and <a href="https://en.wikipedia.org/wiki/Longtermism" title="Longtermism">Longtermism</a>‚Äù (as summarized and linked in Wikipedia). In essence, all of these ideologies envision a future ‚Äúbeyond humanity‚Äù itself, though with different variations. Many argue that cultivating a distant sci-fi future into existence is a supreme ethical goal, outweighing say the ecological survival of planet Earth or the near-term wellbeing of most humans.</p>
<p>If you want a readable summary of these ideas and their influence, <em>More Everything Forever</em><span class="citation" data-cites="beckerMoreEverythingForever2025"><a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></span> is your guided tour. Torres and comedian Kate Willett‚Äôs podcast <em>Dystopia Now</em> (<a href="https://podcasts.apple.com/us/podcast/dystopia-now/id1794217765">Apple</a> | <a href="https://open.spotify.com/show/1buHPmi0O4OHKI4vp1Kmpn">Spotify</a>) is a regular look at this world.</p>
<div class="no-row-height column-margin column-container"><div id="fn10"><p><sup>10</sup>&nbsp;Adam Becker, <em>More Everything Forever: AI Overlords, Space Empires, and Silicon Valley‚Äôs Crusade to Control the Fate of Humanity</em> (Basic Books, 2025).</p></div></div></section>
<section id="limitations-of-implementing-ai-in-workplace-settings" class="level2">
<h2 class="anchored" data-anchor-id="limitations-of-implementing-ai-in-workplace-settings">Limitations of implementing AI in workplace settings</h2>
<p>Upwork <a href="https://www.upwork.com/research/ai-enhanced-work-models">research</a> ‚Äúsurveying 2,500 global C-suite executives, full-time employees, and freelancers in the U.S., UK, Australia, and Canada‚Äù:</p>
<blockquote class="blockquote">
<p>The majority of AI use appears to be emerging bottoms up, with workers leading the charge. Now, leaders are eager to channel this enthusiasm. Among the increased demands executives have placed on workers in the past year, requesting they use AI tools to increase their output tops the list (37%). Already 39% of companies require employees to use AI tools, with an additional 46% encouraging employees to use the tools without mandating that they do so.</p>
</blockquote>
<blockquote class="blockquote">
<p>However, this new technology has not yet fully delivered on this productivity promise: Nearly half (47%) of employees using AI say they have no idea how to achieve the productivity gains their employers expect, and <strong>77% say these tools have actually decreased their productivity</strong> and added to their workload.</p>
</blockquote>
<blockquote class="blockquote">
<p>For example, survey respondents reported that they‚Äôre spending more time reviewing or moderating AI-generated content (39%), invest more time learning to use these tools (23%), and are now being asked to do more work (21%).</p>
</blockquote>
<p><a href="https://x.com/mayowaoshin/status/1833557628401627245?s=61"><strong>Technology author Mayo Olshin</strong></a>: ‚ÄúIf however, you simply‚Äùtrust‚Äù the Al outputs due to lack of knowledge, skill, or willingness to review results, the long term damage will outweigh the initial productivity gains you got so ‚Äúhyped‚Äù about.‚Äù A <a href="https://mastodon.online/@david_chisnall@infosec.exchange/113690087176624006">similar experience from <strong>David Chisnall</strong> on CoPilot</a>: ‚ÄúIt has cost me more time than it has saved.‚Äù</p>
</section>
<section id="recent-books" class="level2">
<h2 class="anchored" data-anchor-id="recent-books">Recent books</h2>
<p>Many of the perspectives described above have been articulated into <strong>new books</strong> published in the past year or so including:</p>
<ul>
<li>Becker, Adam. <em>More Everything Forever: AI Overlords, Space Empires, and Silicon Valley‚Äôs Crusade to Control the Fate of Humanity</em>. Basic Books, 2025.</li>
<li>Bender, Emily M., and Alex Hanna. <em>The AI Con: How to Fight Big Tech‚Äôs Hype and Create the Future We Want ‚Äì Exposing Surveillance Capitalism and Artificial Intelligence Myths in Information Technology Today</em>. Harper, 2025.</li>
<li>Hao, Karen. <em>Empire of AI: Dreams and Nightmares in Sam Altman‚Äôs OpenAI</em>. Penguin Press, 2025.</li>
<li>Marcus, Gary F. <em>Taming Silicon Valley: How We Can Ensure That AI Works for Us</em>. The MIT Press, 2024.</li>
</ul>


</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/carwilb\.github\.io\/quarto-website");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../index.html#posts" class="pagination-link" aria-label="Posts">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Posts</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../posts/ai-wikimedia.html" class="pagination-link" aria-label="The Wikimedia Foundation, Wikipedia, and Artificial Intelligence">
        <span class="nav-page-text">The Wikimedia Foundation, Wikipedia, and Artificial Intelligence</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Carwil Bjork-James‚Äôs research, teaching, and data science website</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This page is built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>